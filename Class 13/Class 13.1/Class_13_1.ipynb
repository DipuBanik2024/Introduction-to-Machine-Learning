{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Preprocessing**\n",
        "# **Stemming and Lemmatization in NLP**"
      ],
      "metadata": {
        "id": "3LjNkUoq7lh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming**"
      ],
      "metadata": {
        "id": "jkgRR5Vv7844"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v78lINjXzY1t",
        "outputId": "b5f080f9-d98d-4790-cee5-0070b4358d2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nltk - natural langauge tool kit"
      ],
      "metadata": {
        "id": "oHPr-iB-zjEe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "sFdxMXp3zoM-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port = PorterStemmer()"
      ],
      "metadata": {
        "id": "59NYjZOp1F1Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['improve','improving','improvements','improved','improver']\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2DBmLX91PL3",
        "outputId": "7b614e1f-ae23-4ee4-95b4-194f400f1a86"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['improve', 'improving', 'improvements', 'improved', 'improver']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print('Before = ',word)\n",
        "  print('After = ',port.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emcLNI0G1Xd3",
        "outputId": "13c05642-4079-48cd-95c9-f3dc48a3b49c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before =  improve\n",
            "After =  improv\n",
            "Before =  improving\n",
            "After =  improv\n",
            "Before =  improvements\n",
            "After =  improv\n",
            "Before =  improved\n",
            "After =  improv\n",
            "Before =  improver\n",
            "After =  improv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "port.stem('Moon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Tgi1DnER2tXP",
        "outputId": "0e69d6a7-406b-42c7-b21b-9de2f375459d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'moon'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "port.stem('physics')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lz1A1XD026Ov",
        "outputId": "c1656142-c27d-496e-9fd3-caebc9d9fc4b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'physic'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lemmatization**"
      ],
      "metadata": {
        "id": "cc9ov6-72993"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "# Download WordNet\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# (Optional, but recommended for POS tagging)\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGjmffLW3A2u",
        "outputId": "d97d54e7-01f6-4d77-908e-f05caf84a351"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "_pg9rFNp37aw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print('Before =', word)\n",
        "    print('After  =', lem.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x68AWWo4OMP",
        "outputId": "7ca546ff-4452-4d69-a524-0e7da1b342e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before = improve\n",
            "After  = improve\n",
            "Before = improving\n",
            "After  = improving\n",
            "Before = improvements\n",
            "After  = improvement\n",
            "Before = improved\n",
            "After  = improved\n",
            "Before = improver\n",
            "After  = improver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem.lemmatize('running')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9JHsIxLp4yqI",
        "outputId": "372870aa-a39f-4a23-aafa-2467095205b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'running'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separate the words from sentance"
      ],
      "metadata": {
        "id": "amKXlW6B4_KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in  the field of Natural Language Processing that are used to prepare text, words, and documents for further  processing.\"\n"
      ],
      "metadata": {
        "id": "0asSisBy5Bpn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_udMMcst5C4f",
        "outputId": "fcc7fd9c-263e-4101-d733-c92eda49f7d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen = word_tokenize(sentence)\n",
        "sen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-319-Qy5LnX",
        "outputId": "453a735f-1d11-46e8-d8e3-99254ff64534"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Stemming',\n",
              " 'and',\n",
              " 'Lemmatization',\n",
              " 'are',\n",
              " 'Text',\n",
              " 'Normalization',\n",
              " '(',\n",
              " 'or',\n",
              " 'sometimes',\n",
              " 'called',\n",
              " 'Word',\n",
              " 'Normalization',\n",
              " ')',\n",
              " 'techniques',\n",
              " 'in',\n",
              " 'the',\n",
              " 'field',\n",
              " 'of',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'that',\n",
              " 'are',\n",
              " 'used',\n",
              " 'to',\n",
              " 'prepare',\n",
              " 'text',\n",
              " ',',\n",
              " 'words',\n",
              " ',',\n",
              " 'and',\n",
              " 'documents',\n",
              " 'for',\n",
              " 'further',\n",
              " 'processing',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sen:\n",
        "    print(lem.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu5nptMo5ndP",
        "outputId": "9f28e5d4-86c9-475f-ee52-34ffe4fdb311"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming\n",
            "and\n",
            "Lemmatization\n",
            "are\n",
            "Text\n",
            "Normalization\n",
            "(\n",
            "or\n",
            "sometimes\n",
            "called\n",
            "Word\n",
            "Normalization\n",
            ")\n",
            "technique\n",
            "in\n",
            "the\n",
            "field\n",
            "of\n",
            "Natural\n",
            "Language\n",
            "Processing\n",
            "that\n",
            "are\n",
            "used\n",
            "to\n",
            "prepare\n",
            "text\n",
            ",\n",
            "word\n",
            ",\n",
            "and\n",
            "document\n",
            "for\n",
            "further\n",
            "processing\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sen:\n",
        "    print(port.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tgRJfcz5s1x",
        "outputId": "57be149e-87fe-4400-beb9-8db1b796d5b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stem\n",
            "and\n",
            "lemmat\n",
            "are\n",
            "text\n",
            "normal\n",
            "(\n",
            "or\n",
            "sometim\n",
            "call\n",
            "word\n",
            "normal\n",
            ")\n",
            "techniqu\n",
            "in\n",
            "the\n",
            "field\n",
            "of\n",
            "natur\n",
            "languag\n",
            "process\n",
            "that\n",
            "are\n",
            "use\n",
            "to\n",
            "prepar\n",
            "text\n",
            ",\n",
            "word\n",
            ",\n",
            "and\n",
            "document\n",
            "for\n",
            "further\n",
            "process\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3rcM6jW53QH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords,words\n",
        "import string"
      ],
      "metadata": {
        "id": "K-BF8Bmh6GVf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eIJAYz3I6INf",
        "outputId": "6898fcd0-6645-4e71-caeb-09fb5b4efb5f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords.words('english') #these will delete"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXOiI3Af6ST_",
        "outputId": "91802e32-94f2-4171-fd04-a5e91df310bd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8g9kWoi6l-R",
        "outputId": "0051a7fc-209e-4235-d525-513eeecec25e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('bengali')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNQlGlx06pII",
        "outputId": "9b6f9ec5-0fb1-47dd-dcf8-cf74067b16ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['অতএব',\n",
              " 'অথচ',\n",
              " 'অথবা',\n",
              " 'অনুযায়ী',\n",
              " 'অনেক',\n",
              " 'অনেকে',\n",
              " 'অনেকেই',\n",
              " 'অন্তত',\n",
              " 'অন্য',\n",
              " 'অবধি',\n",
              " 'অবশ্য',\n",
              " 'অর্থাত',\n",
              " 'আই',\n",
              " 'আগামী',\n",
              " 'আগে',\n",
              " 'আগেই',\n",
              " 'আছে',\n",
              " 'আজ',\n",
              " 'আদ্যভাগে',\n",
              " 'আপনার',\n",
              " 'আপনি',\n",
              " 'আবার',\n",
              " 'আমরা',\n",
              " 'আমাকে',\n",
              " 'আমাদের',\n",
              " 'আমার',\n",
              " 'আমি',\n",
              " 'আর',\n",
              " 'আরও',\n",
              " 'ই',\n",
              " 'ইত্যাদি',\n",
              " 'ইহা',\n",
              " 'উচিত',\n",
              " 'উত্তর',\n",
              " 'উনি',\n",
              " 'উপর',\n",
              " 'উপরে',\n",
              " 'এ',\n",
              " 'এঁদের',\n",
              " 'এঁরা',\n",
              " 'এই',\n",
              " 'একই',\n",
              " 'একটি',\n",
              " 'একবার',\n",
              " 'একে',\n",
              " 'এক্',\n",
              " 'এখন',\n",
              " 'এখনও',\n",
              " 'এখানে',\n",
              " 'এখানেই',\n",
              " 'এটা',\n",
              " 'এটাই',\n",
              " 'এটি',\n",
              " 'এত',\n",
              " 'এতটাই',\n",
              " 'এতে',\n",
              " 'এদের',\n",
              " 'এব',\n",
              " 'এবং',\n",
              " 'এবার',\n",
              " 'এমন',\n",
              " 'এমনকী',\n",
              " 'এমনি',\n",
              " 'এর',\n",
              " 'এরা',\n",
              " 'এল',\n",
              " 'এস',\n",
              " 'এসে',\n",
              " 'ঐ',\n",
              " 'ও',\n",
              " 'ওঁদের',\n",
              " 'ওঁর',\n",
              " 'ওঁরা',\n",
              " 'ওই',\n",
              " 'ওকে',\n",
              " 'ওখানে',\n",
              " 'ওদের',\n",
              " 'ওর',\n",
              " 'ওরা',\n",
              " 'কখনও',\n",
              " 'কত',\n",
              " 'কবে',\n",
              " 'কমনে',\n",
              " 'কয়েক',\n",
              " 'কয়েকটি',\n",
              " 'করছে',\n",
              " 'করছেন',\n",
              " 'করতে',\n",
              " 'করবে',\n",
              " 'করবেন',\n",
              " 'করলে',\n",
              " 'করলেন',\n",
              " 'করা',\n",
              " 'করাই',\n",
              " 'করায়',\n",
              " 'করার',\n",
              " 'করি',\n",
              " 'করিতে',\n",
              " 'করিয়া',\n",
              " 'করিয়ে',\n",
              " 'করে',\n",
              " 'করেই',\n",
              " 'করেছিলেন',\n",
              " 'করেছে',\n",
              " 'করেছেন',\n",
              " 'করেন',\n",
              " 'কাউকে',\n",
              " 'কাছ',\n",
              " 'কাছে',\n",
              " 'কাজ',\n",
              " 'কাজে',\n",
              " 'কারও',\n",
              " 'কারণ',\n",
              " 'কি',\n",
              " 'কিংবা',\n",
              " 'কিছু',\n",
              " 'কিছুই',\n",
              " 'কিন্তু',\n",
              " 'কী',\n",
              " 'কে',\n",
              " 'কেউ',\n",
              " 'কেউই',\n",
              " 'কেখা',\n",
              " 'কেন',\n",
              " 'কোটি',\n",
              " 'কোন',\n",
              " 'কোনও',\n",
              " 'কোনো',\n",
              " 'ক্ষেত্রে',\n",
              " 'কয়েক',\n",
              " 'খুব',\n",
              " 'গিয়ে',\n",
              " 'গিয়েছে',\n",
              " 'গিয়ে',\n",
              " 'গুলি',\n",
              " 'গেছে',\n",
              " 'গেল',\n",
              " 'গেলে',\n",
              " 'গোটা',\n",
              " 'চলে',\n",
              " 'চান',\n",
              " 'চায়',\n",
              " 'চার',\n",
              " 'চালু',\n",
              " 'চেয়ে',\n",
              " 'চেষ্টা',\n",
              " 'ছাড়া',\n",
              " 'ছাড়াও',\n",
              " 'ছিল',\n",
              " 'ছিলেন',\n",
              " 'জন',\n",
              " 'জনকে',\n",
              " 'জনের',\n",
              " 'জন্য',\n",
              " 'জন্যওজে',\n",
              " 'জানতে',\n",
              " 'জানা',\n",
              " 'জানানো',\n",
              " 'জানায়',\n",
              " 'জানিয়ে',\n",
              " 'জানিয়েছে',\n",
              " 'জে',\n",
              " 'জ্নজন',\n",
              " 'টি',\n",
              " 'ঠিক',\n",
              " 'তখন',\n",
              " 'তত',\n",
              " 'তথা',\n",
              " 'তবু',\n",
              " 'তবে',\n",
              " 'তা',\n",
              " 'তাঁকে',\n",
              " 'তাঁদের',\n",
              " 'তাঁর',\n",
              " 'তাঁরা',\n",
              " 'তাঁাহারা',\n",
              " 'তাই',\n",
              " 'তাও',\n",
              " 'তাকে',\n",
              " 'তাতে',\n",
              " 'তাদের',\n",
              " 'তার',\n",
              " 'তারপর',\n",
              " 'তারা',\n",
              " 'তারৈ',\n",
              " 'তাহলে',\n",
              " 'তাহা',\n",
              " 'তাহাতে',\n",
              " 'তাহার',\n",
              " 'তিনঐ',\n",
              " 'তিনি',\n",
              " 'তিনিও',\n",
              " 'তুমি',\n",
              " 'তুলে',\n",
              " 'তেমন',\n",
              " 'তো',\n",
              " 'তোমার',\n",
              " 'থাকবে',\n",
              " 'থাকবেন',\n",
              " 'থাকা',\n",
              " 'থাকায়',\n",
              " 'থাকে',\n",
              " 'থাকেন',\n",
              " 'থেকে',\n",
              " 'থেকেই',\n",
              " 'থেকেও',\n",
              " 'দিকে',\n",
              " 'দিতে',\n",
              " 'দিন',\n",
              " 'দিয়ে',\n",
              " 'দিয়েছে',\n",
              " 'দিয়েছেন',\n",
              " 'দিলেন',\n",
              " 'দু',\n",
              " 'দুই',\n",
              " 'দুটি',\n",
              " 'দুটো',\n",
              " 'দেওয়া',\n",
              " 'দেওয়ার',\n",
              " 'দেওয়া',\n",
              " 'দেখতে',\n",
              " 'দেখা',\n",
              " 'দেখে',\n",
              " 'দেন',\n",
              " 'দেয়',\n",
              " 'দ্বারা',\n",
              " 'ধরা',\n",
              " 'ধরে',\n",
              " 'ধামার',\n",
              " 'নতুন',\n",
              " 'নয়',\n",
              " 'না',\n",
              " 'নাই',\n",
              " 'নাকি',\n",
              " 'নাগাদ',\n",
              " 'নানা',\n",
              " 'নিজে',\n",
              " 'নিজেই',\n",
              " 'নিজেদের',\n",
              " 'নিজের',\n",
              " 'নিতে',\n",
              " 'নিয়ে',\n",
              " 'নিয়ে',\n",
              " 'নেই',\n",
              " 'নেওয়া',\n",
              " 'নেওয়ার',\n",
              " 'নেওয়া',\n",
              " 'নয়',\n",
              " 'পক্ষে',\n",
              " 'পর',\n",
              " 'পরে',\n",
              " 'পরেই',\n",
              " 'পরেও',\n",
              " 'পর্যন্ত',\n",
              " 'পাওয়া',\n",
              " 'পাচ',\n",
              " 'পারি',\n",
              " 'পারে',\n",
              " 'পারেন',\n",
              " 'পি',\n",
              " 'পেয়ে',\n",
              " 'পেয়্র্',\n",
              " 'প্রতি',\n",
              " 'প্রথম',\n",
              " 'প্রভৃতি',\n",
              " 'প্রযন্ত',\n",
              " 'প্রাথমিক',\n",
              " 'প্রায়',\n",
              " 'প্রায়',\n",
              " 'ফলে',\n",
              " 'ফিরে',\n",
              " 'ফের',\n",
              " 'বক্তব্য',\n",
              " 'বদলে',\n",
              " 'বন',\n",
              " 'বরং',\n",
              " 'বলতে',\n",
              " 'বলল',\n",
              " 'বললেন',\n",
              " 'বলা',\n",
              " 'বলে',\n",
              " 'বলেছেন',\n",
              " 'বলেন',\n",
              " 'বসে',\n",
              " 'বহু',\n",
              " 'বা',\n",
              " 'বাদে',\n",
              " 'বার',\n",
              " 'বি',\n",
              " 'বিনা',\n",
              " 'বিভিন্ন',\n",
              " 'বিশেষ',\n",
              " 'বিষয়টি',\n",
              " 'বেশ',\n",
              " 'বেশি',\n",
              " 'ব্যবহার',\n",
              " 'ব্যাপারে',\n",
              " 'ভাবে',\n",
              " 'ভাবেই',\n",
              " 'মতো',\n",
              " 'মতোই',\n",
              " 'মধ্যভাগে',\n",
              " 'মধ্যে',\n",
              " 'মধ্যেই',\n",
              " 'মধ্যেও',\n",
              " 'মনে',\n",
              " 'মাত্র',\n",
              " 'মাধ্যমে',\n",
              " 'মোট',\n",
              " 'মোটেই',\n",
              " 'যখন',\n",
              " 'যত',\n",
              " 'যতটা',\n",
              " 'যথেষ্ট',\n",
              " 'যদি',\n",
              " 'যদিও',\n",
              " 'যা',\n",
              " 'যাঁর',\n",
              " 'যাঁরা',\n",
              " 'যাওয়া',\n",
              " 'যাওয়ার',\n",
              " 'যাওয়া',\n",
              " 'যাকে',\n",
              " 'যাচ্ছে',\n",
              " 'যাতে',\n",
              " 'যাদের',\n",
              " 'যান',\n",
              " 'যাবে',\n",
              " 'যায়',\n",
              " 'যার',\n",
              " 'যারা',\n",
              " 'যিনি',\n",
              " 'যে',\n",
              " 'যেখানে',\n",
              " 'যেতে',\n",
              " 'যেন',\n",
              " 'যেমন',\n",
              " 'র',\n",
              " 'রকম',\n",
              " 'রয়েছে',\n",
              " 'রাখা',\n",
              " 'রেখে',\n",
              " 'লক্ষ',\n",
              " 'শুধু',\n",
              " 'শুরু',\n",
              " 'সঙ্গে',\n",
              " 'সঙ্গেও',\n",
              " 'সব',\n",
              " 'সবার',\n",
              " 'সমস্ত',\n",
              " 'সম্প্রতি',\n",
              " 'সহ',\n",
              " 'সহিত',\n",
              " 'সাধারণ',\n",
              " 'সামনে',\n",
              " 'সি',\n",
              " 'সুতরাং',\n",
              " 'সে',\n",
              " 'সেই',\n",
              " 'সেখান',\n",
              " 'সেখানে',\n",
              " 'সেটা',\n",
              " 'সেটাই',\n",
              " 'সেটাও',\n",
              " 'সেটি',\n",
              " 'স্পষ্ট',\n",
              " 'স্বয়ং',\n",
              " 'হইতে',\n",
              " 'হইবে',\n",
              " 'হইয়া',\n",
              " 'হওয়া',\n",
              " 'হওয়ায়',\n",
              " 'হওয়ার',\n",
              " 'হচ্ছে',\n",
              " 'হত',\n",
              " 'হতে',\n",
              " 'হতেই',\n",
              " 'হন',\n",
              " 'হবে',\n",
              " 'হবেন',\n",
              " 'হয়',\n",
              " 'হয়তো',\n",
              " 'হয়নি',\n",
              " 'হয়ে',\n",
              " 'হয়েই',\n",
              " 'হয়েছিল',\n",
              " 'হয়েছে',\n",
              " 'হয়েছেন',\n",
              " 'হল',\n",
              " 'হলে',\n",
              " 'হলেই',\n",
              " 'হলেও',\n",
              " 'হলো',\n",
              " 'হাজার',\n",
              " 'হিসাবে',\n",
              " 'হৈলে',\n",
              " 'হোক',\n",
              " 'হয়']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords.words('bengali'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZNEPF4w6tf_",
        "outputId": "004e93e4-0d7d-4975-c971-9a4872e3e333"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "398"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE7tynva663_",
        "outputId": "39b506fc-25d0-4c87-e054-b28eebd89e3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['albanian',\n",
              " 'arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'belarusian',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'tamil',\n",
              " 'turkish']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}